# RealMySQL - 16. 궁금&실사용 정리

## 페이징 쿼리

단순히 limit으로 조회하게 되면 사용하지 않을 페이지들을 읽게되므로, 뒤로 갈수록 부하가 더 커진다.

따라서 `테이블의 프라이머리 키값 id를 SELECT 쿼리의 조건절에 넣어주기만 하면 된다.`

`이전`, `현재 페이지` ,`다음` 이런식으로 하게 된다.

실제 사용하는 `request dto` 와 `response dto`, `querydsl` 은 다음과 같다.

```kotlin
/** 
 * request
 **/
val offsetId: I		 		// 정렬 기준 id (직전 페이징 결과의 마지막 id)
val limit: Long 			// 총 검색할 개수
val orderBy: String? 	// 정렬 기준 (내림차순, 오름차순)
```

```kotlin
/** 
 * response
 */
val contents: List<T>	// 내용
val offsetId: I				// 마지막 id+1
val limit: Long				// 요청한 개수
val hasNext: Boolean	// 다음 검색할 내용이 있는지 여부

/**
 * hasNext값을 주기 위해서 contents는 limit+1로 조회하고, 
 * 따라서 hasNext는 contents.size > limit 값이다.
 *
 * 다음 요청은 받은 offsetId를 그대로 전달하면 된다.
 **/
```

```kotlin
/**
 * querydsl
 **/
from(table)
  .where(
    table.id.gt(offsetId)
  ).orderBy(table.id.asc())
  .select(table.id)
  .distinct()
  .limit(limit+1)
  .fetch()
```

## 시퀀스 사용하기

auto increment 말고 시퀀스를 사용하는 이유...?

> [Hibernate Batch/Bulk Insert/Update](https://hangouts.google.com/hangouts/_/calendar/aGVlYmcyQGdtYWlsLmNvbQ.108ae79976nvrj0obbcbsjq0c5?authuser=0)

> [Spring Data에서 Batch Insert 최적화](https://homoefficio.github.io/2020/01/25/Spring-Data%EC%97%90%EC%84%9C-Batch-Insert-%EC%B5%9C%EC%A0%81%ED%99%94/)



`@GeneratedValue` = `GenerationType.AUTO`가 기본

하지만, Spring Boot 2.0.x에서는 Hibernate **5.2.x** 버전을 사용하는데,

이건 **Table sequence** generators가 적용되어있다.

> 공용 시퀀스 테이블을 두고 모든 테이블의 id 시퀀스를 한테이블에서 관리하는 방식입니다.
> 자세한 내용은 ([링크](https://vladmihalcea.com/hibernate-identity-sequence-and-table-sequence-generator/))를 참고하세요!

> 참고 : [Spring Boot Data JPA 2.0 에서 id Auto_increment 문제 해결](https://jojoldu.tistory.com/295?category=635883)



따라서 우리가 원하는 형식으로 하려면 

> 1. application.properties/yml의 `use-new-id-generator-mappings`을 **false**로 설정한다
> 2. `@GeneratedValue`의 전략을 `GenerationType.IDENTITY`로 지정한다
>
> 참고 : [Spring Boot Data JPA 2.0 에서 id Auto_increment 문제 해결](https://jojoldu.tistory.com/295?category=635883)



## 복제

### read-only

실제로 어떻게 적용하는가?

`aws rds(aurora mysql)`에서 `add reader` 버튼 클릭하면 `reader` 가 자동으로 추가됩니다.

`jdbcUrl`에는 `writer` 와 `reader` `endpoint` 를 `,` 로 연결해서 써주면, `readOnly` 트랜잭션은 자동으로 `reader` 로 붙습니다.

```yaml
spring:
  profiles: prod
  datasource:
    jdbcUrl: jdbc:mysql:aurora://writer_endpoint:port,reader_endpoint:port/table?connectTimeout=1000&socketTimeout=60000&useSSL=false
```

> Amazon Aurora *DB cluster*는 하나 이상의 DB 인스턴스와 이 DB 인스턴스의 데이터를 관리하는 클러스터 볼륨으로 구성됩니다. Aurora *클러스터 볼륨*은 다중 가용 영역을 아우르는 가상 데이터베이스 스토리지 볼륨으로서, 각 가용 영역에는 DB 클러스터 데이터의 사본이 있습니다. Aurora DB 클러스터는 다음과 같이 두 가지 유형의 DB 인스턴스로 구성됩니다.
>
> 
>
> https://docs.aws.amazon.com/ko_kr/AmazonRDS/latest/AuroraUserGuide/Aurora.Overview.html



![cluster](https://user-images.githubusercontent.com/21075774/79004059-eec9da80-7b8e-11ea-8326-df0be577d41a.png)

> 출처 - https://linux.systemv.pe.kr/aws-aurora-endpoint-and-was-connection-pool/



## 백업

우리는 어떻게 쓰는가?

잘은 모르겠는데 이런 문서가 있네

[Aurora DB 클러스터 백업 및 복원에 대한 개요](https://docs.aws.amazon.com/ko_kr/AmazonRDS/latest/AuroraUserGuide/Aurora.Managing.Backups.html)

> Aurora DB 클러스터는 내결함성을 고려하여 설계되었습니다. 클러스터 볼륨은 단일 AWS 리전에 속하는 다중 가용 영역을 모두 아우르며, 각 가용 영역에는 클러스터 볼륨 데이터의 사본이 복사됩니다. 이 기능은 가용 영역 한 곳에서 결함이 발생하더라도 DB 클러스터가 잠시 서비스가 중단될 뿐 전혀 데이터 손실 없이 결함을 견딜 수 있음을 의미합니다.

> 단일 마스터 복제를 사용하는 DB 클러스터의 기본 인스턴스에 결함이 발생하면 Aurora이 다음 두 가지 방법 중 하나를 사용하여 자동으로 새로운 기본 인스턴스로 장애 조치합니다.
>
> - 기존 Aurora 복제본을 새 기본 인스턴스로 승격시킴
> - 새로운 기본 인스턴스 만들기



### 히스토리

히스토리? 이력관리로는 `hibernate	` 의   ` nvers` 테이블을 사용한다.

> Hibernate Envers 프로젝트는 각각의 대상 엔티티의 이력관리를 간편하게 도와줍니다. 정말 간단하게 적용하자면 `@Audited`어노테이션만 붙이면 끝납니다.

> 출처: https://haviyj.tistory.com/40 [What do you want?]

```java
@Audited
@AuditTable("table_audit")
@Entity
```



> 좀 더 풀어서 설명하자면 Book 도메인에 `@Audited`를 사용하여 이력관리를 하기 위해서는 이력관리용 테이블로 book_aud 테이블(이름 변경 가능)과 revinfo 테이블이 필요합니다.
>
> book_aud는 book의 필드값 3개(id, title, publishedAt)와 
>
> 이력관리 ID값인 `rev`, 타입을 나타내는 `revtype`으로 설계됩니다. `revtype`값의 의미는 다음과 같습니다.
>
> #### revtype
>
> - 0 : insert
> - 1 : update
> - 2 : delete
>
> 
>
> 출처: https://haviyj.tistory.com/40 [What do you want?]

```mysql
DROP TABLE IF EXISTS REVINFO;
CREATE TABLE REVINFO
(
    REV      BIGINT NOT NULL AUTO_INCREMENT,
    REVTSTMP BIGINT DEFAULT NULL,
    PRIMARY KEY (REV)
)
    ENGINE = InnoDB
    DEFAULT CHARSET = utf8mb4
    COMMENT ='Hibernate Envers Revisions';

```

```mysql
DROP TABLE IF EXISTS table_audit;
CREATE TABLE table_audit
(
    id      							 BIGINT NOT NULL,
    REV                    BIGINT NOT NULL,
    REVTYPE                TINYINT,

    column1		             BIGINT,
    column2                VARCHAR(100),
    
    PRIMARY KEY (id, REV),
)
    ENGINE = InnoDB
    DEFAULT CHARSET = utf8mb4
    COMMENT = 'table audit';

```

> 이력관리 테이블을 위해 RevisionRepository 인터페이스가 있으니 상속해서 사용하면 된다.
>
> 사용하기 위해선 아래와같이 추가하면 된다.
>
> ```mysql
> @EnableJpaRepositories(repositoryFactoryBeanClass = EnversRevisionRepositoryFactoryBean.class) //EnversRevisionRepositoryFactoryBean 인스턴스 생성
> @SpringBootApplication
> public class Application {
> 
> 	public static void main(String[] args) {
> 		SpringApplication.run(Application.class, args);
> 	}
> }
> ```
>
> 출처: https://haviyj.tistory.com/40 [What do you want?]



## 모니터링

우리는 aws rds를 사용하기 때문에 거기 모니터링을 사용함.

하지만, 로그로 남겨 따로 모니터링 하기 위해 `prometheus` 모니터링을 이용하고 `metricbeat` 를 사용한다.

> (모니터링 시스템에 대해선 나중에..........)

그리고 `db connection pool` 은 `hikari cp` 를 사용하기 때문에 `elk` 에서 `prometheus.metrics.hikaricp....`로  접근해서 볼 수 있다.



왜 `hikari cp`?

> 기존에 SpringBoot에선 tomcat-jdbc를 기본 Datasource 로 제공했었는데요.
> **2.0부터 HikariCP가 기본**으로 변경되었습니다. 
>
> 출처: https://jojoldu.tistory.com/296 
